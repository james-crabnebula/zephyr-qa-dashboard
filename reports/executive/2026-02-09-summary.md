---
title: "QA Executive Summary"
date: 2026-02-09
category: executive
tags: [summary, overview, qa]
author: James Barclay
status: complete
build_version: 0.1.4
---

# Zephyr Agency Nightly — QA Executive Summary

| Field | Value |
|-------|-------|
| **Version** | Zephyr Agency Nightly v0.1.4 |
| **Test Dates** | 5–6 February 2026 |
| **QA Lead** | James Barclay (Q-A Methodology) |
| **Testers** | Alex Lohr, Cristian Vogel, Robin van Boven |
| **Platforms** | macOS ARM64, Windows 11, Ubuntu 24.04, Fedora 42, Pop!_OS 22.04 |
| **Sessions** | 7 across 3 testers and 5 platforms |
| **Test Steps** | 871 executed across 70 test cases in 8 suites |

---

## How This Report Works

This report pack is designed for AI-assisted development. It connects QA findings directly to your dev workflow.

### What was tested

Three experienced testers ran 70 structured test cases across 8 functional areas of Zephyr Agency Nightly v0.1.4. Testing was black-box — no source access, only the shipped nightly build. Each tester worked through the same test suites independently on their own platform, recording pass/fail results and detailed notes. Results are stored in a SQLite database (`testing.db`) with 871 individual test steps, 32 curated issues, and 47 screenshot evidence files.

### Report structure

| File | Audience | Contains |
|------|----------|----------|
| `00-executive-summary.md` | Leadership | Verdict, numbers, recommendations |
| `01-authentication.md` — `08-installation.md` | Dev team | Issues with investigation prompts |

### How to use the area reports

Each area report (01 through 08) contains every issue found in that area. For each issue you get:

1. **What's broken** — the observed behaviour, who found it, on which platforms
2. **Tester evidence** — direct quotes from the testers who encountered the issue
3. **Cross-platform comparison** — whether the issue is platform-specific or universal
4. **Remediation workflow** — a structured process for investigating and fixing the issue, designed for AI-assisted development

### The remediation workflow

Each issue includes a remediation section built on a six-phase workflow:

```
PRE-FLIGHT → INVESTIGATE → FIX → TEST → VALIDATE → CHECKPOINT
```

| Phase | What to do |
|-------|-----------|
| **PRE-FLIGHT** | Reproduce the bug. Confirm you can see the behaviour described. Identify the relevant source files. |
| **INVESTIGATE** | Copy the investigation prompt into your AI coding tool (Claude, Cursor, Copilot). It tells the AI what to search for, where to look, and what the expected behaviour should be. |
| **FIX** | Implement the changes identified during investigation. |
| **TEST** | Write a regression test covering the fix. Each issue includes what to assert — describe the expected behaviour so the bug cannot silently return. The test should fail before the fix and pass after. |
| **VALIDATE** | Verify the fix against the validation criteria listed for that issue. Each issue states what "fixed" looks like. |
| **CHECKPOINT** | Confirm the fix doesn't regress other functionality. Mark the issue as resolved. |

### Using the investigation prompts

The investigation prompts are fenced code blocks you can copy directly into your AI coding assistant. Each one:

- Describes the observed problem and expected behaviour
- Suggests where to look in the Tauri/SolidJS codebase (based on black-box observations and Tauri patterns)
- Lists specific things to check
- Is written so an AI coding tool can act on it immediately

**Workflow:** Open the relevant area report → find the issue → copy the investigation prompt → paste into Claude/Cursor/Copilot → follow the AI's guidance → validate against the criteria → move to the next issue.

### Priority order

Work through issues in severity order: CRITICAL first, then HIGH. MEDIUM and LOW can be batched or deferred. The CRITICAL issues table above shows the four issues that should be addressed before the next nightly build.

---

## Verdict

Zephyr Agency Nightly v0.1.4 is **not ready for customer-facing release**. The core AI chat feature is non-functional, unauthenticated users can read and post content (a security issue), offline data is lost on restart, and the application does not launch on any tested Linux distribution. Of 871 test steps executed, 583 passed (85% of steps with a definitive result), but the 4 CRITICAL issues represent fundamental failures in authentication, core functionality, data persistence, and platform support that must be resolved before any public release.

---

## Severity Breakdown

| Severity | Count | Description |
|----------|-------|-------------|
| **CRITICAL** | 4 | Blocks core functionality or poses security/data-loss risk |
| **HIGH** | 7 | Significant feature broken or unusable |
| **MEDIUM** | 13 | Feature works but behaviour deviates from expectations |
| **LOW** | 8 | Cosmetic, UX polish, or minor inconsistencies |
| **Total** | **32** | |

---

## Pass Rate by Suite

| Suite | Tests | Pass | Fail | Blocked | N/A | Pass Rate |
|-------|-------|------|------|---------|-----|-----------|
| 00 Pre-Launch & Setup | 147 | 67 | 10 | 1 | 69 | 85.9% |
| 01 Authentication | 108 | 89 | 7 | 8 | 4 | 85.6% |
| 02 Settings | 127 | 105 | 13 | 1 | 8 | 88.2% |
| 03 Chat | 98 | 63 | 18 | 4 | 13 | **74.1%** |
| 04 Specialists | 95 | 61 | 9 | 4 | 21 | 82.4% |
| 05 Knowledge | 71 | 52 | 4 | 0 | 15 | **92.9%** |
| 06 Workflows | 92 | 63 | 5 | 3 | 21 | 88.7% |
| 07 Tasks | 133 | 83 | 10 | 6 | 34 | 83.8% |

Pass rate = P / (P + F + B). Chat is the weakest area; Knowledge Garden is the strongest.

---

## CRITICAL Issues

| ID | Area | Summary |
|----|------|---------|
| INST-04 | Installation | Linux: App fails to launch on all three tested distros (Ubuntu, Fedora, Pop!_OS) |
| AUTH-01 | Authentication | Unauthenticated users can view channel content and post messages as "Anonymous User" |
| CHAT-06 | Chat | AI chat messaging completely non-functional — no responses on any platform |
| CHAT-11 | Chat | Offline messages are lost on app restart — data loss risk |

---

## HIGH Issues

| ID | Area | Summary |
|----|------|---------|
| INST-06 | Installation | Fullscreen mode breaks window layout with black artifacts (Windows 11) |
| AUTH-03 | Authentication | Auth flow: 403 redirect, spam folder confirmation email, browser window not closed |
| AUTH-04 | Authentication | Google OAuth window hangs unresponsive during auth flow |
| SET-04 | Settings | Dark theme makes sidebar illegible — white text on white background |
| SET-08 | Settings | Package Manager: "Registry Unavailable", no packages listed |
| SET-09 | Settings | GitHub token settings link throws Tauri ACL error |
| TASK-05 | Tasks | Kanban drag-and-drop broken; persistent state corruption after crash |

---

## Per-Area Summary

| Area | Pass Rate | CRIT | HIGH | MED | LOW | Report |
|------|-----------|------|------|-----|-----|--------|
| Installation & Setup | 85.9% | 1 | 1 | — | 1 | [08-installation.md](08-installation.md) |
| Authentication | 85.6% | 1 | 2 | 1 | — | [01-authentication.md](01-authentication.md) |
| Settings | 88.2% | — | 3 | 1 | 1 | [02-settings.md](02-settings.md) |
| Chat | 74.1% | 2 | — | 2 | 1 | [03-chat.md](03-chat.md) |
| Specialists | 82.4% | — | — | 2 | 1 | [04-specialists.md](04-specialists.md) |
| Knowledge | 92.9% | — | — | 2 | 1 | [05-knowledge.md](05-knowledge.md) |
| Workflows | 88.7% | — | — | 2 | 3 | [06-workflows.md](06-workflows.md) |
| Tasks | 83.8% | — | 1 | 3 | — | [07-tasks.md](07-tasks.md) |

---

## Tester Coverage Matrix

| Suite | Alex (macOS) | Cristian (macOS) | Robin (Win11) | Robin (Linux x3) |
|-------|--------------|------------------|---------------|-------------------|
| 00 Pre-Launch & Setup | Day 1 | Day 1, Day 2 | Day 2 | Day 1 |
| 01 Authentication | Day 1 | Day 1, Day 2 | Day 2 | — |
| 02 Settings | Day 1 | Day 1, Day 2 | Day 2 | — |
| 03 Chat | Day 1 | Day 1, Day 2 | Day 2 | — |
| 04 Specialists | Day 1 | Day 2 | Day 2 | — |
| 05 Knowledge | Day 1 | Day 2 | Day 2 | — |
| 06 Workflows | Day 1 | Day 2 | Day 2 | — |
| 07 Tasks | Day 1 | Day 2 | Day 2 | — |

Linux sessions were blocked at suite 00 (app would not launch). Cristian completed suites 00–03 on Day 1 and continued 00–07 on Day 2.

---

## Pass Rate by Platform

| Platform | Steps Tested | Pass Rate | Key Finding |
|----------|-------------|-----------|-------------|
| macOS ARM64 | 498 | 92.5% | Best platform; AUTH-01 and CHAT-06 still present |
| Windows 11 | 310 | 75.4% | Most failures; thorough testing revealed UI and theme issues |
| Linux (all distros) | 63 | 80.0% | App does not launch — only installer steps tested |

---

## Recommendations

1. **Escalate AUTH-01 immediately** — Unauthenticated content access is a security defect. No content should be visible before sign-in.

2. **Fix CHAT-06 before next nightly** — AI chat is the core product feature. It is completely non-functional. This blocks meaningful testing of AI-assisted workflows, specialists, and tasks.

3. **Investigate Linux platform failures** — Three distributions, three different failure modes. A decision is needed: fix Linux support for launch, or formally drop it from the v1 target and document as known limitation.

4. **Address CHAT-11 offline data loss** — If the product claims local-first or offline capabilities, messages must survive app restart. If offline is not a v1 feature, the UI should not imply that it is.

5. **Continue nightly builds** — The test infrastructure and suites are in place. Future nightlies should be re-tested once CRITICAL issues are resolved.

6. **Windows 11 needs attention** — 75.4% pass rate with the most failures of any platform. Dark theme, fullscreen, and ACL issues suggest the Windows build may be receiving less development attention than macOS.

---

*Report generated 2026-02-09 by Q-A Methodology. Data source: testing.db (871 steps, 32 issues, 47 screenshots, 7 sessions).*
